% This is "sig-alternate.tex" V2.0 May 2012
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate}
\usepackage{color}
\usepackage[colorlinks,citecolor=blue]{hyperref}

\begin{document}

\conferenceinfo{Web Science}{2016 DIKU, Denmark}
\title{WS 2016 Project 2}
\numberofauthors{1} 
\author{
\alignauthor 
Anonymous
}
\maketitle



\section{Introduction}
There are many examples of people extracting the sentiment of sentences using machine learning. The goal of of this report is to examine how these methods translates into product specific contexts and compare the results. This is done using product reviews from    brickset.com\cite{lego}, using the data set found here\cite{data} and using the python package textblob\cite{textblob} and the deep learning tool nlp\cite{nlp}. 

\section{Methodology}
All preprocessing has been done in Python\cite{python}. Training and testing using textblob has also been done in python. The deep learning tool provided by Stanford nlp does most of the processing for us after the data have been preprocessed by Python. The code consist of the modules that correspond to the following sections
\subsection{General pre-processing of data }
The product review data provided in the google sheet\cite{data} is missing data. The data that is not complete is filtered so only valid data, with a valid sentiment data point is used for further investigation.

This step reduces the data from 4901 data points to 3893 data points
\subsection{Textblob sentiment}
Before the Textblob model could be trained, the data had to go through some extra preprocessing. To speedup the training process, every product review is converted to a textblob object. 

The data is then split using Numpys\cite{numpy} Kfold function to prepare for 3 fold validation. The model is then trained using the three data subsets provided by the Kfold function, and then tested using the test subsets provided by the same Kfold call.

\subsection{Stanford recursive deep learning for sentiment analysis}
This sections has not been comleted


\section{Findings}
Looking at the data, it can be observed, that 55.89\% of the data is positive. So naively guessing that everything as positive, would yield this approximate result, assuming the data we have represents the data.

\subsection{Textblob based}
Textblob only manages to match the baseline approximated above. There is close to no preprocessing done on the data, so there is a high probability that this can be improved.
\subsection{Stanford coreNLP}
No completed model

\subsection{External sentiment calculator}
I started out by measuring how a normal not product related sentiment analyser worked, i used uClassify\cite{uClassify} combined with it's python api\cite{uClassifyp}. 

Using this the result is slightly better than the Textblob based one, with a 60\% success. This is mostly due to the fact, that most of the result is ignored and treated as neutral. The reason for this is, that some reviews may be negative or positive, but not towards the product.

\section{Conclusions}


% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{citations}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns
%\appendix
%Appendix A
%\balancecolumns % GM June 2007
% That's all folks!
\end{document}
